{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. **Licensed under the GNU General Public License v3.0**\n",
    "\n",
    "# Train your own Model and Deploy to Device\n",
    "\n",
    "## Semantic segmentation with UNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to train a model using Azure Machine Learning and deploy it to the Azure Percept DK. The model implementation is based on https://github.com/milesial/Pytorch-UNet with some modifications,\n",
    "and is therefore taken under GPLv3.0.  \n",
    "\n",
    "This notebook is intended to run on an [Azure ML remote compute instance](https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-instance). To get started, make a directory in your AML workspace called \"unet-notebook\" and then upload this notebook to that directory,\n",
    "then run through each cell. This notebook will download the GitHub repository and train a U-Net to do semantic segmentation of bananas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1616090738981
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Get the repository and cd into the right directory\n",
    "!git clone https://github.com/microsoft/azure-percept-advanced-development.git\n",
    "%cd azure-percept-advanced-development/machine-learning-notebooks/train-from-scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616090777512
    }
   },
   "outputs": [],
   "source": [
    "# These packages are pre-installed on an Azure ML remote compute instance\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = 20,20\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616090790683
    }
   },
   "outputs": [],
   "source": [
    "# Use the default datasore associated with the current workspace\n",
    "from azureml.core import Workspace\n",
    "from azureml.core import Dataset\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "datastore = ws.get_default_datastore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616090862050
    }
   },
   "outputs": [],
   "source": [
    "# Upload our data to the datastore\n",
    "root_data_path = './data'\n",
    "data_path = 'datasets/bananas_dataset'\n",
    "datastore.upload(src_dir=root_data_path, target_path=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616090876525
    }
   },
   "outputs": [],
   "source": [
    "# Register the uploaded data as an Azure ML datatset, so it can be accessed from the compute cluster doing the training\n",
    "dataset = Dataset.File.from_files(path=(datastore, data_path))\n",
    "dataset = dataset.register(workspace=ws, name='bananas_dataset', description='bananas unet training data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616090879323
    }
   },
   "outputs": [],
   "source": [
    "# Define input/output locations\n",
    "root_outputs_path = './outputs'\n",
    "train_path = os.path.join(root_data_path, 'images')\n",
    "mask_path = os.path.join(root_data_path, 'masks')\n",
    "\n",
    "model_path = os.path.join(root_outputs_path, \"model\")\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "model_file = os.path.join(model_path, \"bananas.pth\")\n",
    "\n",
    "onnx_path = os.path.join(root_outputs_path, \"onnx\")\n",
    "if not os.path.exists(onnx_path):\n",
    "    os.makedirs(onnx_path)\n",
    "onnx_output = os.path.join(onnx_path, \"bananas.onnx\")\n",
    "\n",
    "ir_output_path = os.path.join(root_outputs_path, \"intel\")\n",
    "if not os.path.exists(ir_output_path):\n",
    "    os.makedirs(ir_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Draw a sample image and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616090884534
    }
   },
   "outputs": [],
   "source": [
    "file_name = \"2021-01-11T224237.988294Z\"\n",
    "img_file = os.path.join(train_path, f\"{file_name}.jpg\")\n",
    "mask_file = os.path.join(mask_path, f\"{file_name}.png\")\n",
    "\n",
    "os.path.exists(img_file), os.path.exists(mask_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616090888835
    }
   },
   "outputs": [],
   "source": [
    "sample = cv2.imread(img_file)\n",
    "\n",
    "# OpenCV doesn't read .gif files. Workaround\n",
    "mask_pil = Image.open(mask_file)\n",
    "mask = np.array(mask_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616090892678
    }
   },
   "outputs": [],
   "source": [
    "def draw_image_mask(sample, mask):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 20))\n",
    "    ax[0].imshow(cv2.cvtColor(sample, cv2.COLOR_BGR2RGB))\n",
    "    ax[0].axis('off')\n",
    "    ax[0].title.set_text('Sample Image')\n",
    "    ax[1].imshow(mask)\n",
    "    ax[1].axis('off')\n",
    "    ax[1].title.set_text('Sample Mask')\n",
    "    \n",
    "draw_image_mask(sample, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Provision a GPU compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616090964461
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "ws = Workspace.from_config() \n",
    "\n",
    "# Choose a name for your compute cluster\n",
    "cluster_name = \"gpu1\"\n",
    "\n",
    "# Verify that the cluster does not exist already\n",
    "try:\n",
    "    cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    vm_size = \"STANDARD_NC6\"  # This is a smallish GPU node. Make sure to use a subscription that has this.\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size=vm_size,\n",
    "                                                           idle_seconds_before_scaledown=2400,\n",
    "                                                           min_nodes=0,\n",
    "                                                           max_nodes=1)\n",
    "    cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the model on the GPU cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616092474021
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core import Experiment\n",
    "from azureml.core import Environment\n",
    "from azureml.core import ScriptRunConfig\n",
    "from azureml.core import Dataset\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "dataset = Dataset.get_by_name(workspace=ws, name='bananas_dataset')\n",
    "\n",
    "experiment = Experiment(workspace=ws, name='bananas-experiment')\n",
    "\n",
    "config = ScriptRunConfig(\n",
    "    source_directory='.',\n",
    "    script='train.py',\n",
    "    compute_target='gpu1',\n",
    "    arguments=[\n",
    "        '--data-path', dataset.as_named_input('input').as_mount(),\n",
    "        '--output-path', './outputs',\n",
    "        '--epochs', 3,\n",
    "        '--batch-size', 2,\n",
    "        '--learning-rate', 0.001,\n",
    "        '--scale', 0.5,\n",
    "        '--to-bgr'\n",
    "    ],\n",
    ")\n",
    "# set up the training environment\n",
    "env = Environment.from_conda_specification(\n",
    "    name='train-env',\n",
    "    file_path='./train-env.yml'\n",
    ")\n",
    "# use a customized docker image \n",
    "env.docker.base_image = None\n",
    "env.docker.base_dockerfile = \"./Dockerfile\" \n",
    "config.run_config.environment = env\n",
    "\n",
    "run = experiment.submit(config)\n",
    "aml_url = run.get_portal_url()\n",
    "print(\"Submitted to compute cluster. You can monitor the run progress using the link below:\")\n",
    "print(aml_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1616092709073
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Monitor the progress with Tensorboard\n",
    "from azureml.tensorboard import Tensorboard\n",
    "\n",
    "local_logdir = \"./outputs/logs\"\n",
    "tb = Tensorboard([run], local_root=local_logdir, port=6006)\n",
    "tb.stop()  # Make sure to stop any previous TensorBoard instances\n",
    "\n",
    "!rm -rf $local_logdir\n",
    "tblink = tb.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1616094430384
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Wait until the experiment run is completed.\n",
    "run.wait_for_completion(show_output=True)\n",
    "\n",
    "# Kill Tensorboard\n",
    "tb.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616094531192
    }
   },
   "outputs": [],
   "source": [
    "# Get the model from the latest completed run outputs\n",
    "import glob\n",
    "from azureml.core import Experiment\n",
    "\n",
    "completed_run = None\n",
    "\n",
    "experiment = Experiment(workspace=ws, name='bananas-experiment')\n",
    "runs = experiment.get_runs()\n",
    "\n",
    "for r in runs:\n",
    "    if r.get_status() == 'Completed':\n",
    "        completed_run = r\n",
    "        break\n",
    "if completed_run == None:        \n",
    "    print(\"No completed run available\")\n",
    "else:\n",
    "    completed_run.download_file('outputs/checkpoints/model.pth', model_file)\n",
    "    print(f'Downloaded model file: {model_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Infer using the original model\n",
    "\n",
    "This simply validates that the model works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616094641377
    }
   },
   "outputs": [],
   "source": [
    "import unet\n",
    "\n",
    "device = torch.device('cpu')\n",
    "net = unet.UNet(n_channels=3, n_classes=1, bilinear=False)\n",
    "net.to(device=device)\n",
    "net.load_state_dict(torch.load(model_file, map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616094928952
    }
   },
   "outputs": [],
   "source": [
    "# We scale the image by this factor during training\n",
    "scale_factor = 0.5\n",
    "\n",
    "def prep_img_for_inference(sample, scale_factor=0.5):\n",
    "    img = torch.from_numpy(cv2.resize(sample, None, fx=scale_factor, fy=scale_factor)).to(device)\n",
    "    # convert to CHW from HWC\n",
    "    img = img.permute(2, 0, 1)\n",
    "    # convert to NCHW\n",
    "    img = img.unsqueeze(0)\n",
    "    # convert from the OpenCV byte representation\n",
    "    img = img.type(torch.FloatTensor)\n",
    "    # scale to [0..1]\n",
    "    img /= 255\n",
    "    return img\n",
    "\n",
    "img = prep_img_for_inference(sample, scale_factor=scale_factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipe it through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616095024854
    }
   },
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "def post_process(output, threshold=0.5, has_probs=False):\n",
    "    if not has_probs:\n",
    "        probs = torch.sigmoid(output)\n",
    "    else:\n",
    "        probs = output\n",
    "    probs = probs.squeeze(0)\n",
    "\n",
    "    out_mask = (probs > threshold).cpu().numpy().astype(\"int\") * 255\n",
    "    return out_mask\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    output = net(img)\n",
    "    out_mask = post_process(output, threshold=threshold)\n",
    "    \n",
    "out_mask = np.squeeze(out_mask, 0)\n",
    "draw_image_mask(cv2.cvtColor(sample[:,:,::-1], cv2.COLOR_BGR2RGB), out_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How accurate? \n",
    "Compute Dice Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616095080391
    }
   },
   "outputs": [],
   "source": [
    "from dice_loss import dice\n",
    "dice(cv2.resize(mask, (out_mask.shape[1], out_mask.shape[0])), out_mask)  # cv2.resize expects (width, height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Convert the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The original code did not have output activation. Bake it in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616095083656
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(net, nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep the input dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616095086599
    }
   },
   "outputs": [],
   "source": [
    "dummy_input = prep_img_for_inference(sample)\n",
    "print(f\"These will be the fixed dimensions of any incoming images: {dummy_input.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the conversion with the right opset_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616095093617
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# opset_version = 11 to support up-convolutional layers\n",
    "torch.onnx.export(model, dummy_input, onnx_output, opset_version=11, \n",
    "                  export_params=True, input_names=[\"input\"], output_names=[\"output\"], verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Check with ONNX Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616095099171
    }
   },
   "outputs": [],
   "source": [
    "# We are going to use a CPU-based version of ONNX runtime in order\n",
    "# to avoid CUDA compat problems\n",
    "%pip install onnxruntime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616095106202
    }
   },
   "outputs": [],
   "source": [
    "import onnx\n",
    "onnx_model = onnx.load(onnx_output)\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform inference with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616095115905
    }
   },
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "ort_session = onnxruntime.InferenceSession(onnx_output)\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "sample_input = prep_img_for_inference(sample)\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(sample_input)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616095119065
    }
   },
   "outputs": [],
   "source": [
    "out_mask = post_process(torch.from_numpy(ort_outs[0]), threshold=threshold, has_probs=True)\n",
    "out_mask = np.squeeze(out_mask, 0)\n",
    "draw_image_mask(sample, out_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Convert the ONNX model to IR format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616095123545
    }
   },
   "outputs": [],
   "source": [
    "# Volume to bind to the OpenVINO container\n",
    "pwd = !pwd\n",
    "src_vol = os.path.join(pwd[0], 'outputs')\n",
    "src_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616095389402
    }
   },
   "outputs": [],
   "source": [
    "# Convert in the OpenVINO container\n",
    "!docker run --rm -v $src_vol:/working -w /working openvino/ubuntu18_dev:2021.1 \\\n",
    "        python3 \"/opt/intel/openvino_2021/deployment_tools/model_optimizer/mo.py\" \\\n",
    "        --input_model \"./onnx/bananas.onnx\" -o \"./intel\" --input \"input\" --output \"output\" --scale 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Use OpenVINO to compile IR format to blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile outputs/compile.sh\n",
    "#!/bin/bash\n",
    "\n",
    "# OpenVINO compilation script\n",
    "\n",
    "source /opt/intel/openvino_2021/bin/setupvars.sh\n",
    "\n",
    "/opt/intel/openvino_2021/deployment_tools/inference_engine/lib/intel64/myriad_compile \\\n",
    "    -m intel/bananas.xml -o intel/bananas.blob -VPU_NUMBER_OF_SHAVES 8 -VPU_NUMBER_OF_CMX_SLICES 8 -ip U8 -op FP32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616095527107
    }
   },
   "outputs": [],
   "source": [
    "# Run compilation in the container (this takes a few minutes)\n",
    "!docker run --rm -v $src_vol:/working -w /working openvino/ubuntu18_dev:2021.1 /bin/bash compile.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Package up blob for delivery to devkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile 'outputs/intel/config.json'\n",
    "{\n",
    "    \"DomainType\": \"unet\",\n",
    "    \"ModelFileName\": \"bananas.blob\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd outputs/intel && zip model.zip bananas.blob config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Upload the blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616095664837
    }
   },
   "outputs": [],
   "source": [
    "# Use the default datatstore for upload\n",
    "ds = ws.get_default_datastore()\n",
    "print(ds.name, ds.datastore_type, ds.account_name, ds.container_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616095668660
    }
   },
   "outputs": [],
   "source": [
    "# Do upload\n",
    "ds.upload_files(['outputs/intel/model.zip'], target_path='models', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616095678466
    }
   },
   "outputs": [],
   "source": [
    "# Install Azure Storage tools \n",
    "%pip install azure-storage-blob==2.1.0 msrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616095700520
    }
   },
   "outputs": [],
   "source": [
    "# Generate download SAS URL for model.zip\n",
    "from datetime import datetime, timedelta\n",
    "from azure.storage.blob import (\n",
    "    BlockBlobService,\n",
    "    ContainerPermissions,\n",
    "    BlobPermissions,\n",
    "    PublicAccess,\n",
    ")\n",
    "   \n",
    "AZURE_ACC_NAME = ds.account_name\n",
    "AZURE_PRIMARY_KEY = ds.account_key\n",
    "AZURE_CONTAINER = ds.container_name\n",
    "AZURE_BLOB=ds.name\n",
    "AZURE_File='models/model.zip' \n",
    "\n",
    "block_blob_service = BlockBlobService(account_name=AZURE_ACC_NAME, account_key=AZURE_PRIMARY_KEY)\n",
    "sas_url = block_blob_service.generate_blob_shared_access_signature(AZURE_CONTAINER,\n",
    "                                                                   AZURE_File,\n",
    "                                                                   permission=BlobPermissions.READ,\n",
    "                                                                   expiry= datetime.utcnow() + timedelta(hours=30*24))\n",
    "downloadurl ='https://'+AZURE_ACC_NAME+'.blob.core.windows.net/'+AZURE_CONTAINER+'/'+AZURE_File+'?'+sas_url\n",
    "print(downloadurl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Perform Module Twin update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616095713792
    }
   },
   "outputs": [],
   "source": [
    "# Install Azure Iot Hub tools\n",
    "%pip install azure-iot-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616095719560
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from azure.iot.hub import IoTHubRegistryManager\n",
    "from azure.iot.hub.models import Twin, TwinProperties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616095726433
    }
   },
   "outputs": [],
   "source": [
    "# Incorporate the connection string, device_id and the module_id values from your IoT Hub\n",
    "# Go to https://portal.azure.com\n",
    "# Select your IoT Hub\n",
    "# Click on Shared access policies\n",
    "# Click 'service' policy on the right (or another policy having 'service connect' permission)\n",
    "# Copy Connection string--primary key\n",
    "\n",
    "CONNECTION_STRING = \"<YOUR-CONNECTION-STRING-PRIMARY-KEY>\"\n",
    "\n",
    "DEVICE_ID = \"<YOUR-DEVICE-NAME>\"\n",
    "# If you have changed the name of the azureeyemodule for some reason,\n",
    "# you will need to change it here too.\n",
    "MODULE_ID = \"azureeyemodule\"\n",
    "\n",
    "iothub_registry_manager = IoTHubRegistryManager(CONNECTION_STRING)\n",
    "module_twin = iothub_registry_manager.get_module_twin(DEVICE_ID, MODULE_ID)\n",
    "\n",
    "print ( \"\" )\n",
    "print ( \"Module twin properties before update    :\" )\n",
    "print ( \"{0}\".format(module_twin.properties) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1616095736565
    }
   },
   "outputs": [],
   "source": [
    "# Update twin\n",
    "twin_patch = Twin()\n",
    "twin_patch.properties = TwinProperties(desired={\"ModelZipUrl\": downloadurl})\n",
    "updated_module_twin = iothub_registry_manager.update_module_twin(DEVICE_ID, MODULE_ID, twin_patch, module_twin.etag)\n",
    "\n",
    "print ( \"\" )\n",
    "print ( \"Module twin properties after update     :\" )\n",
    "print ( \"{0}\".format(updated_module_twin.properties) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model will get pushed to the IoT Edge device via module twin update method.  \n",
    "\n",
    "Check video stream using [VLC media player](https://www.videolan.org/vlc/) on a local PC:\n",
    "1. Select Media -> Open Network Stream…  \n",
    "2. Input the network stream: `rtsp://<ip of the devkit>:8554/result`  \n",
    "3. Click “Play” button.  "
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
