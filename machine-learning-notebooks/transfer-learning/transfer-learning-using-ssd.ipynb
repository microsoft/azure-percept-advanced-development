{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright (c) Microsoft Corporation.\n",
        "Licensed under the MIT License.\n",
        "\n",
        "# Train your own Model and Deploy to Device\n",
        "\n",
        "**NOTE**\n",
        "* Warning: copying *.pb, *.bin, or, *.blob using the web interface can corrupt the files. If needed download and use Azure storage explorer or the CL.\n",
        "* You can run all the cells (after you manually do the first one), but do note that the deployment ones will require some input specific to your device.\n",
        "\n",
        "This notebook shows how to create a Tensorflow object detection model, how to convert the model to the appropriate format for the Perception Development\n",
        "Kit, and how to deploy the model to your kit.\n",
        "\n",
        "This notebook takes a transfer learning approach, using a pre-trained Tensorflow Mobilenet model with custom dataset\n",
        "and SSDLite layers that we will train to detect bowls.\n",
        "We use the [Tensorflow object detection API](https://github.com/tensorflow/models/tree/master/research/object_detection).\n",
        "\n",
        "The trained model will be deployed to the Azure Percept Devkit using the Module Twin Update method."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "uQQ5ihC-ycGn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up the GPU for Tensorflow 1.15\n",
        "\n",
        "We will be using Tensorflow 1.15 for this example, and Tensorflow 2.x examples should be coming soon.\n",
        "\n",
        "The datascience notebook VMs do not come with the appropriate libraries installed for this version of Tensorflow, and so we will need to\n",
        "install them. If your compute node/cluster is a GPU machine, you will want to make sure the appropriate version of CUDA is installed\n",
        "into your VM so that Tensorflow can use it to accelerate training substantially.\n",
        "\n",
        "If you are using a GPU-enabled compute device, you will want to follow these steps. Otherwise, feel free to skip this cell.\n",
        "\n",
        "1. Start your compute instance if it is not already started.\n",
        "1. Select Open Terminal, which should be a button next to your compute and kernel selection boxes.\n",
        "1. Run `conda info -e` to list the available conda environments. There should be an azureml_py36 environment.\n",
        "1. Select azureml_py36 by running `conda activate azureml_py36`\n",
        "1. Uninstall Pytorch and Tensorflow (which depend on the wrong version of CUDA) and the wrong version of CUDA with `conda uninstall cudatoolkit pytorch`\n",
        "1. Install the correct version of CUDA with `conda install cudatoolkit=10.0`\n",
        "\n",
        "You may now close the terminal tab. We will install Tensorflow in a cell of this notebook later."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "Se2G0XW_ycGp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collecting the data\n",
        "\n",
        "In this notebook, we use a custom dataset that will be used to train a model that detects bowls.\n",
        "\n",
        "To compile this dataset, we have a couple of options. First, we could use a labeling tool like [VoTT](https://github.com/microsoft/VoTT) or\n",
        "[LabelImg](https://github.com/tzutalin/labelImg). Just make sure to export the dataset to Pascal VOC format. There should be one XML file for\n",
        "each image, and the XML files should be under annotations/xmls.\n",
        "\n",
        "The other option for compiling a dataset is to use an already existing dataset like COCO and then filter out all the images and annotations\n",
        "that we don't care about. This is the approach we take here.\n",
        "\n",
        "**NOTE:**\n",
        "The first cell in this notebook contains the code necessary to get the dataset and convert it to the format we need. This will involve downloading\n",
        "the entire COCO dataset (train and validation splits for 2017), which is tens of GBs in size. This may not fit in your Azure ML compute's storage.\n",
        "Our recommendation is to run this cell locally (i.e., copy and paste the commands into your own shell and run them), then upload\n",
        "the resulting dataset to Azure via [Azure Storage Explorer](https://azure.microsoft.com/en-us/features/storage-explorer/)."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "RN0t7wf3ycGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install tqdm for Python:\n",
        "# pip install --user tqdm\n",
        "\n",
        "# First, get the Advanced Code Repository\n",
        "#!wget https://github.com/microsoft/azure-percept-advanced-development/archive/main.zip -O azure-percept-advanced-development-main.zip\n",
        "#!unzip azure-percept-advanced-development-main.zip\n",
        "#!rm azure-percept-advanced-development-main.zip\n",
        "#!cd azure-percept-advanced-development-main/machine-learning-notebooks/transfer-learning/scripts\n",
        "\n",
        "# Get the data\n",
        "#!mkdir -p coco/images\n",
        "\n",
        "# Get the 2017 training split\n",
        "#!wget http://images.cocodataset.org/zips/train2017.zip\n",
        "#!unzip train2017.zip\n",
        "#!rm train2017.zip\n",
        "#!mv train2017 coco/images/\n",
        "\n",
        "# Get the 2017 validation split\n",
        "#!wget http://images.cocodataset.org/zips/val2017.zip\n",
        "#!unzip val2017.zip\n",
        "#!rm val2017.zip\n",
        "#!mv val2017 coco/images/\n",
        "\n",
        "# Get all the annotations\n",
        "#!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
        "#!unzip annotations_trainval2017.zip\n",
        "#!rm annotations_trainval2017.zip\n",
        "#!mv annotations coco/annotations\n",
        "\n",
        "# Filter the annotations down to a JSON that only contains images that contain at least one bowl\n",
        "#!python filter_coco.py -i coco/annotations/instances_train2017.json -o coco_train2017_bowls.json -c bowl\n",
        "#!python filter_coco.py -i coco/annotations/instances_val2017.json -o coco_val2017_bowls.json -c bowl\n",
        "\n",
        "# Now create a filtered version of the coco train and val split based on their annotation JSONs\n",
        "#!python create_coco_subset.py -i coco_train2017_bowls.json coco_val2017_bowls.json -g coco/images/train2017 coco/images/val2017 -o coco_filtered\n",
        "\n",
        "# Create Pascal VOC formatted dataset from the COCO subset\n",
        "#!python convert_coco_to_voc.py coco_filtered --target bowls_voc\n",
        "\n",
        "# You should now have a data folder called bowls_voc, which should look like this:\n",
        "# bowls_voc/\n",
        "#   - annotations/\n",
        "#       - xmls/\n",
        "#   - images/\n",
        "\n",
        "# Now upload 'bowls_voc' to your workspace using the Azure Storage Explorer.\n",
        "# To do so, please follow these instructions:\n",
        "# 1. Install Azure Storage Explorer and set it up according to the instructions found here: https://azure.microsoft.com/en-us/features/storage-explorer/\n",
        "# 2. Once your account is linked, you should be able to open Azure Storage Explorer, select the appropriate subscription, storage account, and file share.\n",
        "# 3. Upload 'bowls_voc' to /Users/<your user>/percept-transfer-learning under the appropriate file share.\n",
        "# 4. Make sure that this notebook is in the same folder (/Users/<your user>/percept-transfer-learning)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614822548122
        },
        "id": "nq5aYIbTycGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save current directory for later reference\n",
        "modelroot = !pwd\n",
        "modelroot = modelroot[0]\n",
        "modelroot"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614822548375
        },
        "id": "Pkj1xCSAycG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup workspace for Azure ML\n",
        "!pip install azureml.core\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "print(azureml.core.VERSION)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1614822554091
        },
        "tags": [],
        "id": "Ggi7lGAkycG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install tensorflow v1.15 required for OpenVINO model conversion\n",
        "!pip install tensorflow-gpu==1.15"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614822557429
        },
        "id": "47QAXZ4MycG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Tensor flow models and scripts.\r\n",
        "repository = '--depth 1 --branch v1.13.0 https://github.com/tensorflow/models.git'\r\n",
        "!pip install tf-slim\r\n",
        "!git clone $repository"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614822560974
        },
        "tags": [],
        "id": "Mc1rwE54ycHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required TF packages\n",
        "!sudo -s apt-get install -qq protobuf-compiler python-tk\n",
        "!pip install Cython contextlib2 pillow lxml matplotlib PyDrive pycocotools build utils dataclasses install azure-iot-device azure-iot-hub numpy==1.17"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614822564774
        },
        "tags": [],
        "id": "d4paXYM0ycHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup python path for TF object detection API and TF-Slim\r\n",
        "import os\r\n",
        "import sys\r\n",
        "\r\n",
        "cwd = os.getcwd()\r\n",
        "sys.path.append(cwd)\r\n",
        "\r\n",
        "research = cwd + '/models/research'\r\n",
        "sys.path.append(research)\r\n",
        "\r\n",
        "slim = cwd + '/models/research/slim'\r\n",
        "sys.path.append(slim)\r\n",
        "\r\n",
        "%set_env PYTHONPATH=''\r\n",
        "os.environ['PYTHONPATH'] = research + \":\" + slim +  \":\" + cwd\r\n",
        "os.environ['PYTHONPATH']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614822565009
        },
        "tags": [],
        "id": "F06m52qoycHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update protocol buffers for TF object detection API\r\n",
        "!curl -OL 'https://github.com/google/protobuf/releases/download/v3.2.0/protoc-3.2.0-linux-x86_64.zip'\r\n",
        "\r\n",
        "# Unzip it\r\n",
        "unzipcmd = '-o protoc-3.2.0-linux-x86_64.zip -d protoc3'\r\n",
        "!unzip $unzipcmd\r\n",
        "\r\n",
        "# Put it into /usr/local/bin to put it in the system path\r\n",
        "movecmd = 'mv protoc3/bin/* /usr/local/bin/'\r\n",
        "!sudo $movecmd\r\n",
        "\r\n",
        "# Add header files to the linker's include path\r\n",
        "movecmd = 'mv protoc3/include/* /usr/local/include/'\r\n",
        "!sudo $movecmd"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614822570120
        },
        "tags": [],
        "id": "UrdLfSLUycHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Jump into the tensorflow object detection API research directory\r\n",
        "researchfolder =  modelroot + '/models/research'\r\n",
        "%cd $researchfolder\r\n",
        "\r\n",
        "# As per their installation instructions, compile everything in the protos folder using protoc\r\n",
        "protoccmd = '/usr/local/bin/protoc ' + 'object_detection/protos/*.proto --python_out=.'\r\n",
        "!$protoccmd"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614822574657
        },
        "tags": [],
        "id": "mXRSTPc5ycHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Tensorflow version. OpenVINO currently requires TF 1.x, so that's what we use\r\n",
        "import tensorflow.compat.v1 as tf\r\n",
        "print(tf.__version__)\r\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614822576494
        },
        "tags": [],
        "id": "9X5ZxpG9ycHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run setup for TF object detection API\r\n",
        "args = researchfolder + '/setup.py build'\r\n",
        "!python $args\r\n",
        "\r\n",
        "# Install TF object detection API\r\n",
        "args = researchfolder + '/setup.py install'\r\n",
        "!python $args"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614822918182
        },
        "tags": [
          "outputPrepend"
        ],
        "id": "gR--fg0FycHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run tensorflow model builder test just to make sure we have TF object detection API set up correctly\r\n",
        "args = modelroot + '/models/research/object_detection/builders/model_builder_test.py'\r\n",
        "!python $args"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614822929848
        },
        "tags": [],
        "id": "a7_gKdE8ycHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data folder for training dataset and model\n",
        "%cd $modelroot\n",
        "!mv $modelroot/bowls_voc $modelroot/data\n",
        "%cd data"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614822930126
        },
        "tags": [],
        "id": "ErHYS8EzycHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a little wonky, but we are later on using a script from the TF object detection API,\r\n",
        "# create_pet_tf_record.py to generate a TF record. This script requires certain things in the\r\n",
        "# dataset that we don't have, and which we don't use. We create those things here.\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "image_files = os.listdir('images')\r\n",
        "im_files = [os.path.splitext(x)[0] for x in image_files]\r\n",
        "with open('annotations/trainval.txt', 'w') as text_file:\r\n",
        "  for row in im_files:\r\n",
        "    text_file.write(row + '\\n')\r\n",
        "\r\n",
        "%cd ./annotations\r\n",
        "!mkdir trimaps\r\n",
        "\r\n",
        "image = Image.new('RGB', (640, 480))\r\n",
        "for fname in os.listdir(\"xmls\"):\r\n",
        "  fname, _ = os.path.splitext(fname)\r\n",
        "  image.save(os.path.join(\"trimaps\", fname + \".png\"))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614823596446
        },
        "tags": [],
        "id": "yOXAG2m5ycHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create category labels file for Tensorflow training and validation files (label map)\r\n",
        "label_map_fpath = modelroot + '/models/research/object_detection/data/bowls.pbtxt'\r\n",
        "print(label_map_fpath)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614823596822
        },
        "tags": [],
        "id": "W5kFF7RqycHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $label_map_fpath\r\n",
        "item {\r\n",
        "  id: 1\r\n",
        "  name: 'bowl'\r\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": [],
        "id": "5ZhbS43cycHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix to remove ^M nonprintable char from end of string lines in file created above\r\n",
        "# to see issue run \"!cat -v $label_map_fname\" before and after fix\r\n",
        "with open(label_map_fpath, 'r') as file:\r\n",
        "    label_map_file = file.read()\r\n",
        "update_file = open(label_map_fpath, \"w\")\r\n",
        "update_file.writelines(label_map_file)\r\n",
        "update_file.close() "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614823598673
        },
        "id": "5MZ8Ydd8ycHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Tensorflow training data record files by co-opting this create_pet_tf_record.py script for our purposes\r\n",
        "# This will take a while (tens of minutes probably)\r\n",
        "%cd $modelroot/data\r\n",
        "\r\n",
        "script = modelroot + \"/models/research/object_detection/dataset_tools/create_pet_tf_record.py\"\r\n",
        "args = f\"{script} --label_map_path={label_map_fpath} --data_dir=./ --output_dir=./ --num_shards=1\"\r\n",
        "!python $args\r\n",
        "\r\n",
        "# Now update the names of the output files\r\n",
        "!mv pet_faces_train.record-00000-of-00001 tf_train.record\r\n",
        "!mv pet_faces_val.record-00000-of-00001 tf_val.record"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614824525098
        },
        "tags": [],
        "id": "wvWWs-pyycHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pretrained model for transfer learning: SSD Lite MobileNet V2 COCO\r\n",
        "!curl -OL 'http://download.tensorflow.org/models/object_detection/ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz'\r\n",
        "model_file = os.path.join(modelroot, \"data\", \"ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614824526455
        },
        "tags": [],
        "id": "Thi00zC6ycHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncompress model\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "import glob\r\n",
        "import urllib\r\n",
        "import tarfile\r\n",
        "import urllib.request\r\n",
        "\r\n",
        "tar = tarfile.open(model_file)\r\n",
        "tar.extractall()\r\n",
        "tar.close()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614824529491
        },
        "id": "TrMLAseTycHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare model config file paths and tensorflow configuration file for SSDLiteV2 Model\r\n",
        "config_fname = modelroot + '/models/research/object_detection/samples/configs/ssdlite_mobilenet_retrained.config'\r\n",
        "fine_tune_checkpoint = '\"' + modelroot + '/data/ssdlite_mobilenet_v2_coco_2018_05_09/model.ckpt' + '\"'\r\n",
        "input_path_train = '\"' + modelroot + '/data/tf_train.record' + '\"'\r\n",
        "label_map_path = '\"' + modelroot + '/models/research/object_detection/data/bowls.pbtxt' + '\"'\r\n",
        "input_path_eval = '\"' + modelroot + '/data/tf_val.record' + '\"'"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614824529738
        },
        "id": "oA91GdwXycHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $config_fname\n",
        "model {\n",
        "  ssd {\n",
        "    num_classes: 1\n",
        "    box_coder {\n",
        "      faster_rcnn_box_coder {\n",
        "        y_scale: 10.0\n",
        "        x_scale: 10.0\n",
        "        height_scale: 5.0\n",
        "        width_scale: 5.0\n",
        "      }\n",
        "    }\n",
        "    matcher {\n",
        "      argmax_matcher {\n",
        "        matched_threshold: 0.5\n",
        "        unmatched_threshold: 0.5\n",
        "        ignore_thresholds: false\n",
        "        negatives_lower_than_unmatched: true\n",
        "        force_match_for_each_row: true\n",
        "      }\n",
        "    }\n",
        "    similarity_calculator {\n",
        "      iou_similarity {\n",
        "      }\n",
        "    }\n",
        "    anchor_generator {\n",
        "      ssd_anchor_generator {\n",
        "        num_layers: 6\n",
        "        min_scale: 0.2\n",
        "        max_scale: 0.95\n",
        "        aspect_ratios: 1.0\n",
        "        aspect_ratios: 2.0\n",
        "        aspect_ratios: 0.5\n",
        "        aspect_ratios: 3.0\n",
        "        aspect_ratios: 0.3333\n",
        "      }\n",
        "    }\n",
        "    image_resizer {\n",
        "      fixed_shape_resizer {\n",
        "        height: 300\n",
        "        width: 300\n",
        "      }\n",
        "    }\n",
        "    box_predictor {\n",
        "      convolutional_box_predictor {\n",
        "        min_depth: 0\n",
        "        max_depth: 0\n",
        "        num_layers_before_predictor: 0\n",
        "        use_dropout: false\n",
        "        dropout_keep_probability: 0.8\n",
        "        kernel_size: 3\n",
        "        use_depthwise: true\n",
        "        box_code_size: 4\n",
        "        apply_sigmoid_to_scores: false\n",
        "        conv_hyperparams {\n",
        "          activation: RELU_6,\n",
        "          regularizer {\n",
        "            l2_regularizer {\n",
        "              weight: 0.00004\n",
        "            }\n",
        "          }\n",
        "          initializer {\n",
        "            truncated_normal_initializer {\n",
        "              stddev: 0.03\n",
        "              mean: 0.0\n",
        "            }\n",
        "          }\n",
        "          batch_norm {\n",
        "            train: true,\n",
        "            scale: true,\n",
        "            center: true,\n",
        "            decay: 0.9997,\n",
        "            epsilon: 0.001,\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    feature_extractor {\n",
        "      type: 'ssd_mobilenet_v2'\n",
        "      min_depth: 16\n",
        "      depth_multiplier: 1.0\n",
        "      use_depthwise: true\n",
        "      conv_hyperparams {\n",
        "        activation: RELU_6,\n",
        "        regularizer {\n",
        "          l2_regularizer {\n",
        "            weight: 0.00004\n",
        "          }\n",
        "        }\n",
        "        initializer {\n",
        "          truncated_normal_initializer {\n",
        "            stddev: 0.03\n",
        "            mean: 0.0\n",
        "          }\n",
        "        }\n",
        "        batch_norm {\n",
        "          train: true,\n",
        "          scale: true,\n",
        "          center: true,\n",
        "          decay: 0.9997,\n",
        "          epsilon: 0.001,\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    loss {\n",
        "      classification_loss {\n",
        "        weighted_sigmoid {\n",
        "        }\n",
        "      }\n",
        "      localization_loss {\n",
        "        weighted_smooth_l1 {\n",
        "        }\n",
        "      }\n",
        "      hard_example_miner {\n",
        "        num_hard_examples: 3000\n",
        "        iou_threshold: 0.99\n",
        "        loss_type: CLASSIFICATION\n",
        "        max_negatives_per_positive: 3\n",
        "        min_negatives_per_image: 3\n",
        "      }\n",
        "      classification_weight: 1.0\n",
        "      localization_weight: 1.0\n",
        "    }\n",
        "    normalize_loss_by_num_matches: true\n",
        "    post_processing {\n",
        "      batch_non_max_suppression {\n",
        "        score_threshold: 1e-8\n",
        "        iou_threshold: 0.6\n",
        "        max_detections_per_class: 100\n",
        "        max_total_detections: 100\n",
        "      }\n",
        "      score_converter: SIGMOID\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_config: {\n",
        "  batch_size: 24\n",
        "  optimizer {\n",
        "    rms_prop_optimizer: {\n",
        "      learning_rate: {\n",
        "        exponential_decay_learning_rate {\n",
        "          initial_learning_rate: 0.004\n",
        "          decay_steps: 800720\n",
        "          decay_factor: 0.95\n",
        "        }\n",
        "      }\n",
        "      momentum_optimizer_value: 0.9\n",
        "      decay: 0.9\n",
        "      epsilon: 1.0\n",
        "    }\n",
        "  }\n",
        "  fine_tune_checkpoint: $fine_tune_checkpoint\n",
        "  fine_tune_checkpoint_type:  \"detection\"\n",
        "  num_steps: 200000\n",
        "  data_augmentation_options {\n",
        "    random_horizontal_flip {\n",
        "    }\n",
        "  }\n",
        "  data_augmentation_options {\n",
        "    ssd_random_crop {\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    input_path: $input_path_train\n",
        "  }\n",
        "  label_map_path: $label_map_path\n",
        "}\n",
        "\n",
        "eval_config: {\n",
        "  num_examples: 8000\n",
        "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
        "  # Remove the below line to evaluate indefinitely.\n",
        "  max_evals: 10\n",
        "}\n",
        "\n",
        "eval_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    input_path: $input_path_eval\n",
        "  }\n",
        "  label_map_path: $label_map_path\n",
        "  shuffle: false\n",
        "  num_readers: 1\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": [],
        "id": "goeXNX__ycHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update config file paths\r\n",
        "with open(config_fname, 'r') as f:\r\n",
        "    config_file = f.read()\r\n",
        "config_file = config_file.replace('$fine_tune_checkpoint', fine_tune_checkpoint)\r\n",
        "config_file = config_file.replace('$label_map_path', label_map_path)\r\n",
        "config_file = config_file.replace('$input_path_train', input_path_train)\r\n",
        "config_file = config_file.replace('$input_path_eval', input_path_eval)\r\n",
        "update_file = open(config_fname, 'w')\r\n",
        "update_file.writelines(config_file)\r\n",
        "update_file.close() \r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614824530257
        },
        "id": "LPGdzTCMycHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run tensorflow fine tuning training.\r\n",
        "# To train on CPU instead of GPU uncomment the 'CUDA_VISIBLE_DEVICES' line below\r\n",
        "#\r\n",
        "# Note that we train for 30k steps here. This is sufficient to get reasonable results, though you may prefer to train for longer.\r\n",
        "# **This will take several hours on a GPU compute node, and days on a CPU machine. It would be preferable to run on GPU for faster training. **\r\n",
        "# If your kernel disconnects, don't worry, the code checkpoints periodically, click rerun all cells and it will pick up the latest checkpoint.\r\n",
        "%cd $modelroot\r\n",
        "\r\n",
        "model_dir = os.path.join(modelroot, \"data\", \"retrained\")\r\n",
        "!mkdir $model_dir\r\n",
        "\r\n",
        "import os\r\n",
        "# os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\n",
        "!python ./models/research/object_detection/model_main.py --pipeline_config_path=$config_fname --model_dir=$model_dir --alsologtostderr --num_train_steps=30000 --num_eval_steps=30000"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614830244253
        },
        "tags": [
          "outputPrepend"
        ],
        "id": "Qzl7wPh7ycH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the last checkpoint to use for exporting a frozen graph\r\n",
        "import re\r\n",
        "\r\n",
        "%cd $modelroot/data\r\n",
        "\r\n",
        "lst = os.listdir('retrained')\r\n",
        "lf = filter(lambda k: 'model.ckpt-' in k, lst)\r\n",
        "fileList = str(list(lf))\r\n",
        "checkPointNumbers = re.findall(r'[0-9]+', fileList)\r\n",
        "checkPointNumbers = [int(i) for i in checkPointNumbers]  \r\n",
        "last_model = 'model.ckpt-' + str(max(checkPointNumbers))\r\n",
        "print(last_model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614830244467
        },
        "tags": [],
        "id": "Kg6XeDwiycH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Export frozen graph\r\n",
        "!python $modelroot/models/research/object_detection/export_inference_graph.py --input_type=image_tensor --pipeline_config_path=$config_fname --output_directory=fine_tuned_model --trained_checkpoint_prefix=retrained/$last_model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614830275349
        },
        "tags": [
          "outputPrepend"
        ],
        "id": "EtaYwsDmycH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test inference on photo using frozen graph\n",
        "import tensorflow.compat.v1 as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Path to the frozen graph:\n",
        "PATH_TO_FROZEN_GRAPH = modelroot + '/data/fine_tuned_model/frozen_inference_graph.pb'\n",
        "\n",
        "# Path to the label map\n",
        "PATH_TO_LABEL_MAP = modelroot + '/models/research/object_detection/data/bowls.pbtxt'\n",
        "\n",
        "# Bowl image\n",
        "# Note that because the train/eval split is randomized, it is possible this image was in the train split.\n",
        "IMAGE_PATH = modelroot + '/data/images/bowl_000000084259.jpg'\n",
        "\n",
        "# Number of classes \n",
        "NUM_CLASSES = 1\n",
        "\n",
        "# Minimum confidence value needed to display the bounding box on the image. In range [0.0, 1.0].\n",
        "MIN_THRESHOLD = 0.40\n",
        "\n",
        "# Read the frozen graph\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABEL_MAP)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "# Detection\n",
        "with detection_graph.as_default():\n",
        "    with tf.Session(graph=detection_graph) as sess:\n",
        "        # Read in the image and convert BGR to RGB\n",
        "        image_np = cv2.imread(IMAGE_PATH)[:,:,::-1]\n",
        "\n",
        "        # Expand dimensions since the model expects images to have shape: [1, None, None, 3] \n",
        "        image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "\n",
        "        # Extract image tensor\n",
        "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "        \n",
        "        # Extract detection boxes\n",
        "        boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "        \n",
        "        # Extract detection scores\n",
        "        scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "        \n",
        "        # Extract detection classes\n",
        "        classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "        \n",
        "        # Extract number of detections\n",
        "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "\n",
        "        # Actual detection.\n",
        "        boxes, scores, classes, num_detections = sess.run([boxes, scores, classes, num_detections], feed_dict={image_tensor: image_np_expanded})\n",
        "        print(f\"BOXES (shaped {boxes.shape}):\\n{boxes}\")\n",
        "        print(f\"SCORES (shaped {scores.shape}):\\n{scores}\")\n",
        "        print(f\"CLASSES (shaped {classes.shape}):\\n{classes}\")\n",
        "        print(f\"NDETECTIONS (shaped {num_detections.shape}):\\n{num_detections}\")\n",
        "\n",
        "        # Visualization of the results of a detection.\n",
        "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np,\n",
        "            np.squeeze(boxes),\n",
        "            np.squeeze(classes).astype(np.int32),\n",
        "            np.squeeze(scores),\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            line_thickness=3,\n",
        "            min_score_thresh=MIN_THRESHOLD\n",
        "            )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "tags": [],
        "gather": {
          "logged": 1614830280081
        },
        "id": "nm6HYqq2ycH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display test inference photo\r\n",
        "from matplotlib.pyplot import imshow\r\n",
        "import numpy as np\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "%matplotlib inline\r\n",
        "plt.figure(figsize = (12, 8))\r\n",
        "imshow(image_np)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614830280789
        },
        "id": "T2OLLBMXycH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenVINO\n",
        "\n",
        "At this point, you should have a model exported from Tensorflow and it should be providing good bounding boxes on bowls.\n",
        "The rest of this notebook will show you how to convert the model into the format that the EyeSOM dev kit requires,\n",
        "and then how to download it to your device."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "9OrR0JwTycH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use OpenVINO to convert the frozen graph PB to IR format\n",
        "%cd $modelroot\n",
        "\n",
        "convertCMD = \"docker run --rm -v `pwd`:/working -w /working openvino/ubuntu18_dev:2021.1 \"\n",
        "convertCMD += '/opt/intel/openvino/deployment_tools/model_optimizer/mo_tf.py '\n",
        "convertCMD += '--input_model /working/data/fine_tuned_model/frozen_inference_graph.pb '\n",
        "convertCMD += '--tensorflow_object_detection_api_pipeline_config /working/data/fine_tuned_model/pipeline.config '\n",
        "convertCMD += '--tensorflow_use_custom_operations_config /opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json '\n",
        "convertCMD += '--reverse_input_channels'\n",
        "\n",
        "print(convertCMD)\n",
        "!$convertCMD"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614884622164
        },
        "id": "RY4D9oKjycIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $modelroot/compile.sh\r\n",
        "#!/bin/bash\r\n",
        "\r\n",
        "# OpenVINO compilation script\r\n",
        "\r\n",
        "source /opt/intel/openvino_2021/bin/setupvars.sh\r\n",
        "\r\n",
        "/opt/intel/openvino_2021/deployment_tools/inference_engine/lib/intel64/myriad_compile \\\r\n",
        "    -m /working/frozen_inference_graph.xml -o /working/ssdlite_mobilenet_v2.blob -VPU_NUMBER_OF_SHAVES 8 -VPU_NUMBER_OF_CMX_SLICES 8 -ip U8 -op FP32"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use OpenVINO to compile IR format to blob\r\n",
        "%cd $modelroot\r\n",
        "\r\n",
        "# Run compilation in the container (ignore all the XLink warnings)\r\n",
        "!docker run --rm -v `pwd`:/working -w /working openvino/ubuntu18_dev:2021.1 /bin/bash compile.sh\r\n",
        "\r\n",
        "print(convertCMD)\r\n",
        "!$convertCMD"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614885000332
        },
        "id": "s26sD1r2ycIH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Package up blob for delevery to devkit\r\n",
        "\r\n",
        "# Clean recreate directory if it exists and create it if not \r\n",
        "!rm -rf blob\r\n",
        "!mkdir blob\r\n",
        "\r\n",
        "!cp $modelroot/ssdlite_mobilenet_v2.blob blob/ssdlite_mobilenet_v2.blob"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614885715617
        },
        "id": "KQ6pUtBuycIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $modelroot/blob/labels.txt\r\n",
        "zeroindex\r\n",
        "bowl"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "Z81X4pZLycIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $modelroot/blob/config.json\r\n",
        "{\r\n",
        "    \"DomainType\": \"ssd100\",\r\n",
        "    \"LabelFileName\": \"labels.txt\",\r\n",
        "    \"ModelFileName\": \"ssdlite_mobilenet_v2.blob\"\r\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "g6WcJ0dnycIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Package up model and support files for dev kit\r\n",
        "!cd $modelroot/blob && zip -r model.zip ./*\r\n",
        "%cd $modelroot\r\n",
        "!mv $modelroot/blob/model.zip ./ "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614887188451
        },
        "id": "-d63Jp9mycIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the default datasore associated with the current workspace\n",
        "from azureml.core import Workspace\n",
        "from azureml.core import Dataset\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "ds = ws.get_default_datastore()\n",
        "\n",
        "print(ds.name, ds.datastore_type, ds.account_name, ds.container_name)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614887213662
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model as unencrypted by default\n",
        "MODEL_ENCRYPTED = False"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional - protect the model with Azure Percept SDK\n",
        "\n",
        "# install Azure Percept SDK\n",
        "!pip install sczpy\n",
        "\n",
        "# Declare the Azure account and model management variables to be used for model protection.\n",
        "AZURE_CLIENT_ID='<ENTER YOUR SERVICE PRINCIPAL CLIENT ID>'\n",
        "AZURE_CLIENT_SECRET='<ENTER YOUR SERVICE PRINCIPAL CLIENT SECRET>'\n",
        "AZURE_TENANT_ID='<ENTER YOUR SERVICE PRINCIPAL TENANT ID>'\n",
        "SERVER_URL='<ENTER YOUR AZUURE PERCEPT MM SERVER URL>'\n",
        "MODEL_NAME='<ENTER YOUR MODEL NAME>'\n",
        "MODEL_VERSION='<ENTER YOUR MODEL VERSION>'\n",
        "\n",
        "# Protect the model\n",
        "import sczpy\n",
        "import os\n",
        "\n",
        "os.environ[\"AZURE_CLIENT_ID\"] = AZURE_CLIENT_ID\n",
        "os.environ[\"AZURE_CLIENT_SECRET\"] = AZURE_CLIENT_SECRET\n",
        "os.environ[\"AZURE_TENANT_ID\"] = AZURE_TENANT_ID\n",
        "\n",
        "client = sczpy.SCZClient(SERVER_URL)\n",
        "client.register_model(MODEL_NAME, MODEL_VERSION)\n",
        "os.rename(\"model.zip\", \"model.unencrypted.zip\")\n",
        "client.encrypt(MODEL_NAME, MODEL_VERSION, \"model.unencrypted.zip\", \"model.zip\")\n",
        "client.upload_model(MODEL_NAME, MODEL_VERSION, \"model.zip\")\n",
        "\n",
        "# Set the model tag as encrypted\n",
        "MODEL_ENCRYPTED = True"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the model.zip file to the datastore\n",
        "ds.upload_files(['model.zip'], target_path='transfer-learning-models', overwrite=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614887216569
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Azure Storage tools \n",
        "%pip install azure-storage-blob==2.1.0 msrest"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "_yu2sDVSycIc",
        "gather": {
          "logged": 1614886097610
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate download SAS URL for model.zip\r\n",
        "from datetime import datetime, timedelta\r\n",
        "from azure.storage.blob import (\r\n",
        "    BlockBlobService,\r\n",
        "    ContainerPermissions,\r\n",
        "    BlobPermissions,\r\n",
        "    PublicAccess,\r\n",
        ")\r\n",
        "   \r\n",
        "AZURE_ACC_NAME = ds.account_name\r\n",
        "AZURE_PRIMARY_KEY = ds.account_key\r\n",
        "AZURE_CONTAINER = ds.container_name\r\n",
        "AZURE_BLOB=ds.name\r\n",
        "AZURE_File='transfer-learning-models/model.zip' \r\n",
        "\r\n",
        "block_blob_service = BlockBlobService(account_name=AZURE_ACC_NAME, account_key=AZURE_PRIMARY_KEY)\r\n",
        "sas_url = block_blob_service.generate_blob_shared_access_signature(AZURE_CONTAINER,\r\n",
        "                                                                   AZURE_File,\r\n",
        "                                                                   permission=BlobPermissions.READ,\r\n",
        "                                                                   expiry= datetime.utcnow() + timedelta(hours=30*24))\r\n",
        "downloadurl ='https://'+AZURE_ACC_NAME+'.blob.core.windows.net/'+AZURE_CONTAINER+'/'+AZURE_File+'?'+sas_url\r\n",
        "print(downloadurl)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614887225198
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Azure Iot Hub tools\r\n",
        "%pip install azure-iot-hub"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614886290720
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\r\n",
        "from azure.iot.hub import IoTHubRegistryManager\r\n",
        "from azure.iot.hub.models import Twin, TwinProperties"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614886326006
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Incorporate the connection string, device_id and the module_id values from your IoT Hub\r\n",
        "# Go to https://portal.azure.com\r\n",
        "# Select your IoT Hub\r\n",
        "# Click on Shared access policies\r\n",
        "# Click 'service' policy on the right (or another policy having 'service connect' permission)\r\n",
        "# Copy Connection string--primary key\r\n",
        "CONNECTION_STRING = \"<YOUR-CONNECTION-STRING>\"\r\n",
        "\r\n",
        "DEVICE_ID = \"<YOUR-DEV-ID>\"   # Change this to your device's name as found in the IoT Azure Portal\r\n",
        "MODULE_ID = \"azureeyemodule\"  # Make sure this is what your azureeyemodule is called (check your IoT device in the Azure Portal)\r\n",
        "\r\n",
        "iothub_registry_manager = IoTHubRegistryManager(CONNECTION_STRING)\r\n",
        "module_twin = iothub_registry_manager.get_module_twin(DEVICE_ID, MODULE_ID)\r\n",
        "\r\n",
        "print ( \"\" )\r\n",
        "print ( \"Module twin properties before update    :\" )\r\n",
        "print ( \"{0}\".format(module_twin.properties) )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614887240242
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update twin\n",
        "twin_patch = Twin()\n",
        "if MODEL_ENCRYPTED == True:\n",
        "    twin_patch.properties = TwinProperties(desired={\"ModelZipUrl\": downloadurl, \n",
        "                                                    \"SecureAILifecycleEnabled\": True, \n",
        "                                                    \"SCZ_MODEL_NAME\": MODEL_NAME, \n",
        "                                                    \"SCZ_MODEL_VERSION\": MODEL_VERSION, \n",
        "                                                    \"SCZ_MM_SERVER_URL\": SERVER_URL, \n",
        "                                                    \"DownloadSecuredModelFromMMServer\": False})\n",
        "else:\n",
        "    twin_patch.properties = TwinProperties(desired={\"ModelZipUrl\": downloadurl, \n",
        "                                                    \"SecureAILifecycleEnabled\": False})\n",
        "updated_module_twin = iothub_registry_manager.update_module_twin(DEVICE_ID, MODULE_ID, twin_patch, module_twin.etag)\n",
        "\n",
        "print ( \"\" )\n",
        "print ( \"Module twin properties after update     :\" )\n",
        "print ( \"{0}\".format(updated_module_twin.properties) )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1614887242799
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The trained model will get pushed to the IoT Edge device via module twin update method\r\n",
        "\r\n",
        "Check model inferencing by connecting monitor to the devkit or by installing VLC media player:\r\n",
        "\r\n",
        "Install VLC from https://www.videolan.org/vlc/\r\n",
        "\r\n",
        "Check video stream in VLC:\r\n",
        "\r\n",
        "1. Select Media -> Open Network Stream…\r\n",
        "1. Input the network stream: “rtsp://ip-address-of-your-device:8554/result” then click “Play” button."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "colab": {
      "name": "transfer-learning-using-ssd.ipynb",
      "provenance": []
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
